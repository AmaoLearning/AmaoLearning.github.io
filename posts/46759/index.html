<!DOCTYPE html>
<html lang="cn">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#3367D6"/>
  <link rel="apple-touch-icon" href="/icons-192.png">
  <link rel="manifest" href="/manifest.json">

  <!--将该代码放入博客模板的head中即可-->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  tex2jax: {
  inlineMath: [['$','$'], ['\\(','\\)']],
  processEscapes: true
  }
  });
  </script>
  <!--latex数学显示公式-->
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  <meta name="generator" content="Hexo 7.3.0">

  

  
    <meta name="keywords" content="打工 学习 樱之诗 anime 声优吃 家虎">
  

  
    <meta name="author" content="MaoCaiMao">
  

  

  

  <title>人工智能导论 | 阿毛的小书桌</title>

  

  
    <link rel="shortcut icon" href="/favicon.ico">
  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@1.1.13/index.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/monokai.min.css">
  

  

  
<link rel="stylesheet" href="/css/style.css">

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>
<body>
  <div class="root-container">
    
<!-- header container -->
<header class="header-container post">
  
    <div class="post-image" style="background-image: url(/images/const/banner.png)"></div>
  

  <!-- navbar -->
<nav class="navbar">
  <div class="navbar-content">
    <!-- logo -->
    <div class="navbar-logo">
      <a href="/">
        
          阿毛的小书桌
        
      </a>
    </div>
    <!-- link -->
    <div class="navbar-link">
      <div class="navbar-btn">
        <div></div>
        <div></div>
        <div></div>
      </div>
      <ul class="navbar-list">
        
          <li class="navbar-list-item"><a href="/">首页</a></li>
        
          <li class="navbar-list-item"><a href="/archives">列表</a></li>
        
          <li class="navbar-list-item"><a target="_blank" rel="noopener" href="https://baizhanxu.github.io/">友链</a></li>
        
      </ul>
    </div>
  </div>
</nav>

  
  

  
  

  
  

  
  

  
  
    <div class="header-content">
      <div class="post-text layout-block">
        <div class="layout-margin">
          <h1 class="title-wrap">人工智能导论</h1>
          <h2 class="title-sub-wrap">
            <strong>MaoCaiMao</strong>
            <span>发布于</span>
            <time  class="article-date" datetime="2025-09-17T16:00:00.000Z" itemprop="datePublished">2025-09-18</time>
          </h2>
          
            <h2 class="last-time">
              <span>最后更新于</span>
              <time  class="article-updated" datetime="2025-11-24T11:29:44.178Z" itemprop="dateUpdated">2025-11-24</time>
            </h2>
          
          
          <ul class="wrap-list dark">
  
    <li><a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">📒 学习笔记</a></li>
    
</ul>
          <ul class="wrap-list dark">
  
</ul>
        </div>
      </div>
    </div>
  

  
  
  
</header>

    <!-- 文章 -->

<!-- 文章内容 -->
<div class="body-container">
  <article class="content-container layout-block post-container">
    <div class="article-info">
      
      
      
      
      <section class="article-entry markdown-body layout-margin content-padding--large soft-size--large soft-style--box">
        <p>参考课程：</p>
<ul>
<li>AI3603 SJTU</li>
<li><a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/">CMU 15-281</a></li>
</ul>
<h2 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h2><p>总思路：</p>
<ol>
<li>state</li>
<li>action</li>
<li>openlist</li>
<li>engineering</li>
</ol>
<h3 id="A-算法"><a href="#A-算法" class="headerlink" title="A*算法"></a>A*算法</h3><p>对路径点$n$的评估采用$f(n)=g(n)+h(n)$，其中：</p>
<ul>
<li>$g(n)$表示从起点到n的实际距离。</li>
<li>$h(n)$表示从n到终点的估算距离，常用如欧氏距离、曼哈顿距离（坐标轴平行距离）等，可自定义。</li>
<li>$h(n)$要求Admissible（小于等于实际最优距离）、Consistency（任意两点间的启发式距离小于等于实际最优距离）</li>
<li>在树上只要Admissible即可最优，图上则还要Consistency</li>
</ul>
<p>与其他算法比较：</p>
<ul>
<li>如果$h(n)$为0，该算法退化为Dijkstra算法；</li>
<li>如果$g(n)$为0，该算法退化为只考虑与终点距离的纯贪婪算法。</li>
</ul>
<figure class="highlight pgsql"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"># 来源: https://mat.uab.cat/~alseda/MasterOpt/AStar-Algorithm.pdf<br>Put node_start <span class="hljs-keyword">in</span> the <span class="hljs-keyword">OPEN</span> list <span class="hljs-keyword">with</span> f(node_start) = h(node_start) (initialization)<br><span class="hljs-keyword">while</span> the <span class="hljs-keyword">OPEN</span> list <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> empty &#123;<br>    Take <span class="hljs-keyword">from</span> the <span class="hljs-keyword">open</span> list the node node_current <span class="hljs-keyword">with</span> the lowest<br>        f(node_current) = g(node_current) + h(node_current)<br>    <span class="hljs-keyword">if</span> node_current <span class="hljs-keyword">is</span> node_goal we have <span class="hljs-built_in">found</span> the solution; break<br>    Generate <span class="hljs-keyword">each</span> state node_successor that come <span class="hljs-keyword">after</span> node_current<br>    <span class="hljs-keyword">for</span> <span class="hljs-keyword">each</span> node_successor <span class="hljs-keyword">of</span> node_current &#123;<br>        <span class="hljs-keyword">Set</span> successor_current_cost = g(node_current) + w(node_current, node_successor)<br>        <span class="hljs-keyword">if</span> node_successor <span class="hljs-keyword">is</span> <span class="hljs-keyword">in</span> the <span class="hljs-keyword">OPEN</span> list &#123;<br>            <span class="hljs-keyword">if</span> g(node_successor) ≤ successor_current_cost <span class="hljs-keyword">continue</span><br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> node_successor <span class="hljs-keyword">is</span> <span class="hljs-keyword">in</span> the CLOSED list &#123;<br>            <span class="hljs-keyword">if</span> g(node_successor) ≤ successor_current_cost <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">Move</span> node_successor <span class="hljs-keyword">from</span> the CLOSED list <span class="hljs-keyword">to</span> the <span class="hljs-keyword">OPEN</span> list<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">Add</span> node_successor <span class="hljs-keyword">to</span> the <span class="hljs-keyword">OPEN</span> list<br>            <span class="hljs-keyword">Set</span> h(node_successor) <span class="hljs-keyword">to</span> be the heuristic distance <span class="hljs-keyword">to</span> node_goal<br>        &#125;<br>        <span class="hljs-keyword">Set</span> g(node_successor) = successor_current_cost<br>        <span class="hljs-keyword">Set</span> the parent <span class="hljs-keyword">of</span> node_successor <span class="hljs-keyword">to</span> node_current<br>    &#125;<br>    <span class="hljs-keyword">Add</span> node_current <span class="hljs-keyword">to</span> the CLOSED list<br>&#125;<br><span class="hljs-keyword">if</span>(node_current != node_goal) <span class="hljs-keyword">exit</span> <span class="hljs-keyword">with</span> error (the <span class="hljs-keyword">OPEN</span> list <span class="hljs-keyword">is</span> empty)<br></code></pre></td></tr></table></figure>
<h3 id="Minimax"><a href="#Minimax" class="headerlink" title="Minimax"></a>Minimax</h3><p>零和游戏中，为了做出最佳决策，在有限种情况时，考虑递归地构建所谓决策树。</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/Minimax.svg.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>首先我们需要最大化自己的收益，即树根节点，从而需要在各种情况即第一层子节点中选择，而第一层子节点一般是对手的决策。但理想情况下，对手会选择最大化他的收益、即最小化我们的收益的决策。从而以上分析可以写为：</p>
<script type="math/tex; mode=display">V_0=\max\limits_{a_0}\min\limits_{a_{-0}}(a_0, a_{-0})</script><p>其中$a_0$是我们第一层决策，$a_{-0}$是对手的第一层决策。</p>
<p>Minimax算法就是考虑自己和对手的每一层决策，在所有可能中选择最大化己方收益。可以直观地用递归算法表示：</p>
<figure class="highlight crmsh"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">function minimax(<span class="hljs-keyword">node</span><span class="hljs-title">, depth</span>, maximizingPlayer) is<br>    if depth = <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> <span class="hljs-keyword">node</span> <span class="hljs-title">is</span> a terminal <span class="hljs-keyword">node</span> <span class="hljs-title">then</span><br>        return the heuristic value of <span class="hljs-keyword">node</span><br>    <span class="hljs-title">if</span> maximizingPlayer then<br>        value := −∞<br>        for each child of <span class="hljs-keyword">node</span> <span class="hljs-title">do</span><br>            value := max(value, minimax(child, depth − <span class="hljs-number">1</span>, <span class="hljs-literal">FALSE</span>))<br>        return value<br>    else (* minimizing player *)<br>        value := +∞<br>        for each child of <span class="hljs-keyword">node</span> <span class="hljs-title">do</span><br>            value := min(value, minimax(child, depth − <span class="hljs-number">1</span>, <span class="hljs-literal">TRUE</span>))<br>        return value<br></code></pre></td></tr></table></figure>
<p>在此基础上，我们还可启发式地引入<strong>Alpha-Beta剪枝</strong>。其想法是考虑某个需要最大化收益的节点时，其某些子节点的值已经比考虑过的子节点的结果要小，我们可以放心地不去考虑这些已经比较小的子节点的子树，最小化收益节点同理。例如以下树：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/AB_pruning.svg.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>在算法实现中，我们会设置两个全局变量$\alpha$和$\beta$分别表示已考虑的最大化节点中的最大收益和已考虑的最小化节点中的最小收益。在最大化节点中，我们可以将子节点收益与$\beta$进行比较，即与最大化节点的父节点（最小化节点）的最小收益（最优情况）相比较，显然如果比它大，该子节点就不会被采用，进而排在它后面的其他子节点就不用考虑了。最小化节点也类似，综合起来可以写成如下递归算法：</p>
<figure class="highlight oxygene"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs oxygene"># α=−∞, β=+∞ initially<br><span class="hljs-keyword">function</span> <span class="hljs-title function_">alphabeta</span><span class="hljs-params">(node, depth, α, β, maximizingPlayer)</span> <span class="hljs-title function_">is</span><br>    <span class="hljs-title function_">if</span> <span class="hljs-title function_">depth</span> == 0 <span class="hljs-title function_">or</span> <span class="hljs-title function_">node</span> <span class="hljs-title function_">is</span> <span class="hljs-title function_">terminal</span> <span class="hljs-title function_">then</span><br>        <span class="hljs-title function_">return</span> <span class="hljs-title function_">the</span> <span class="hljs-title function_">heuristic</span> <span class="hljs-title function_">value</span> <span class="hljs-title function_">of</span> <span class="hljs-title function_">node</span><br>    <span class="hljs-title function_">if</span> <span class="hljs-title function_">maximizingPlayer</span> <span class="hljs-title function_">then</span><br>        <span class="hljs-title function_">value</span> := −∞<br>        <span class="hljs-keyword">for</span> <span class="hljs-keyword">each</span> child <span class="hljs-keyword">of</span> node <span class="hljs-keyword">do</span><br>            value := max(value, alphabeta(child, depth − <span class="hljs-number">1</span>, α, β, <span class="hljs-keyword">FALSE</span>))<br>            <span class="hljs-keyword">if</span> value ≥ β <span class="hljs-keyword">then</span><br>                <span class="hljs-keyword">break</span> <span class="hljs-comment">(* β cutoff *)</span><br>            α := max(α, value)<br>        return value<br>    <span class="hljs-keyword">else</span><br>        value := +∞<br>        <span class="hljs-keyword">for</span> <span class="hljs-keyword">each</span> child <span class="hljs-keyword">of</span> node <span class="hljs-keyword">do</span><br>            value := min(value, alphabeta(child, depth − <span class="hljs-number">1</span>, α, β, <span class="hljs-keyword">TRUE</span>))<br>            <span class="hljs-keyword">if</span> value ≤ α <span class="hljs-keyword">then</span><br>                <span class="hljs-keyword">break</span> <span class="hljs-comment">(* α cutoff *)</span><br>            β := min(β, value)<br>        return value<br><br></code></pre></td></tr></table></figure>
<h3 id="Hybrid-A"><a href="#Hybrid-A" class="headerlink" title="Hybrid A*"></a>Hybrid A*</h3><p>用于无人车自动驾驶的改进版A*算法，它考虑了车有朝向和必须转弯的刚体特性，设计了独特的决策模型。车的刚体模型如下图：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/hybrid_kinematic_model.webp" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>转向角度和当前位置会被离散化，方便构建有限的决策树。由此，该模型中每一步新的openlist将会与naive A*不同：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/hybrid_openlist.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>有时可能两种不同的决策会使小车走到同一位置，我们可以通过比如给予转向更少的奖励等手段，剪枝其他决策：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/hybrid_prune.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>最后，启发函数既需要考虑车的刚体特性，还需要考虑路上可能的障碍物。<a target="_blank" rel="noopener" href="https://www.diva-portal.org/smash/get/diva2:1057261/FULLTEXT01.pdf">原论文</a>作者Karl的选择是取不考虑障碍物、仅有刚体特性的<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Dubins_path">Dubins Path</a>或者<a target="_blank" rel="noopener" href="https://lavalle.pl/planning/node822.html">Reeds-Shepp Path</a>（考虑倒车的前者），和仅考虑障碍物的naive A*两种启发式函数中的较大值。两种启发式函数示意图如下：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/hybrid_h.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<h3 id="CSP问题与Backtracking"><a href="#CSP问题与Backtracking" class="headerlink" title="CSP问题与Backtracking"></a>CSP问题与Backtracking</h3><p>Constraint Satisfaction Problems(CSP)是搜索问题的一种，它有着有限的变量、有限的值域和描述了可用子集（一组变量赋值为一个状态）的清晰的约束条件。典型问题有染色问题、排时间表等等。可以将需要赋值的变量视作节点、约束条件视作边，就可以得到一个CSP图。</p>
<p>暴力解法为<strong>Backtracking</strong>（回溯法），即每步给一个变量赋值，检查是否满足约束，不满足则更换赋值甚至往回给上个变量赋值。算法如下：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/csp_backtrack.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>这样做最坏情况需要遍历所有状态，我们希望预知失败，这些方法称为<strong>Filtering</strong>。一种简单的Filtering改进是<strong>Forward Checking</strong>，每给一个变量赋值，我们检查相关约束条件，并更新下个变量可用的值域，这样当可用值域为空集但仍有未赋值变量时就失败了。下面是一个例子：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/csp_forward.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>更进一步，在每一步赋值时，我们还可以检查每两个变量之间的约束条件从而提前发现冲突，这种Filtering方法称为<strong>Arc Consistency</strong>：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/csp_ac3.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>其缺点是只检查两两间约束而忽略全局，时间复杂度高且仍在Backtracking的框架中。</p>
<p>此外，我们可以引入变量<strong>Ordering</strong>来加速发现失败，比如<strong>Minimum Remaining Values</strong>(MRV)优先给那些值域最窄的变量赋值、<strong>Least Constraining Value</strong>(LCV)为变量赋予最少削减其他变量值域的值。</p>
<p>一般的CSP问题使用回溯法时间复杂度最差为$O(d^n)$（d为值域大小，n为变量数），而无环树状CSP时间复杂度最差为$O(nd^2)$（回溯最差$O(nd^2)=O(n)\; arcs \cdot O(d^2) \; backtracking$，赋值最差$O(nd)=O(n)\; nodes \cdot O(d) \; values$）。</p>
<p>总结来说，CSP问题的基础算法为Backtracking，可以使用Filtering(Forward Checking\AC-3), Ordering(MRV\LCV), Special Structure等技巧加速算法。</p>
<p><a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_5_CSP.pdf">参考PPT</a></p>
<h3 id="Local-Search"><a href="#Local-Search" class="headerlink" title="Local Search"></a>Local Search</h3><p>常用于解决CSP问题（如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%AB%E7%9A%87%E5%90%8E%E9%97%AE%E9%A2%98">n皇后问题</a>），但是它通常只记录最佳状态而非全局考虑，目的是在大型问题中以较少的内存寻找一个可以接受的解。对于LS算法，我们用<strong>Complete</strong>和<strong>Optimal</strong>评价其解题能力。我们也经常会绘制问题的状态空间示意图（如下）来观察算法的可行性：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/ls_1.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<ul>
<li><strong>Complete</strong>：如果存在解，算法一定能找到一个解。通常LS算法都是不完备的，就算最优解存在也可能会卡在局部最优解或者平坦高原。</li>
<li><strong>Optimal</strong>：理论保证总能找到最优解。</li>
</ul>
<ol>
<li><strong>迭代优化</strong>：从随机状态出发，迭代地为变量重赋值。比如随机选择造成冲突的变量，为其挑选造成冲突最少的值，直到问题解决。会卡在局部最优解而<em>不完备</em>。</li>
<li><p><strong>（Steeping-ascent）Hill Climbing</strong>：从随机状态出发，贪婪地选择最好的相邻状态直到局部最优解。显然<em>不完备</em>。该算法有许多变种，如局部最优时就从别的起点重新开始的Random-restart Hill Climbing（完备）、根据梯度大小随机选择邻域的Stochastic Hill Climbing、选择第一个更优邻域的First-choice Hill Climbing。</p>
 
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/ls_2.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  </li>
<li><strong>Random Walk</strong>：均匀随机选择邻域。<em>完备</em>但低效。</li>
<li><p><strong>Simulated Annealing</strong>：随机选择邻域，但以一定概率选择表现更差的邻域，概率由温度决定，而温度会以一定曲线随迭代轮数下降。灵感来源于钢铁退火。理论上温度无限时<em>完备</em>且高效。</p>
 
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/ls_3.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
</li>
<li><p><strong>Local Beam Search</strong>：追踪k个状态，每轮选择这k个状态的所有邻域中最好的k个状态。<em>不完备</em>且状态容易聚集。变种如根据表现随机选择k个邻域的Stochastic Beam Search。</p>
</li>
<li><p><strong>Genetic Algorithms</strong>：将状态表达为统一长度编码，从k个状态开始，每次依照表现（Fitness）选择k对父母，每对父母通过交叉（Crossover）产生子嗣，子嗣的编码以一定概率发生变异（Mutation），灵感来源于达尔文进化论。算法的效果取决于Fitness、Selection、Crossover（如PMX、OX）、Mutation（如旅行商问题中可以用简单的编码内交换）等操作的设计水平。轮次有限时<em>不完备</em>。</p>
 
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/ls_4.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
 
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/ls_5.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_6_Local_Search.pdf">参考PPT</a></p>
<h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><h3 id="Markov-Decision-Process（MDP）"><a href="#Markov-Decision-Process（MDP）" class="headerlink" title="Markov Decision Process（MDP）"></a>Markov Decision Process（MDP）</h3><p>强化学习经常可以看成MDP，即每一步行动仅根据当下的状态而选择。MDP中需要理解的概念如下：</p>

    <figure class="figure-image">
      <img src="/images/2025/intro-ai/mdp_1.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>与之相伴的还有经常被使用的<strong>Discount</strong>（奖励随步数指数下降）和常见的<strong>Noise</strong>（有一定概率不选择最佳策略）。</p>
<p>为了得到清晰的Value图，经常使用动态规划中的Bellman方法，存在<strong>Value Iteration</strong>和<strong>Policy Iteration</strong>两种实现。</p>
<ul>
<li><p>Value Iteration每轮检查每个状态是否更新Value直至收敛，每轮时间复杂度$O(|S|^2|A|)$：</p>
  
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/mdp_2.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
</li>
<li><p>Policy Iteration从固定Policy出发，更新完一轮后寻找更好的Policy并重复直至收敛，每轮时间复杂度$O(|S|^2)$：</p>
  
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/mdp_3.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
</li>
<li><p>两种算法的比较：</p>
  
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/mdp_4.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
</li>
</ul>
<p>仅需要解一个状态的Value时：<br>
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/mdp_5.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  </p>
<p>最后，MDP涉及到的公式：<br>
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/mdp_6.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  </p>
<p>MDP是RL的前奏，这一部分中所有状态转移概率、奖励信息都是已知的，所以是一个可以全局考虑的离线问题。但是RL中这些信息可能都未知，就需要试错探索和更新策略，这才是Learning。</p>
<p>参考PPT：<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_14_MDPs_I.pdf">MDP_I</a>、<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_15_MDPs_II.pdf">MDP_II</a></p>
<h3 id="Towards-Reinforcement-Learning"><a href="#Towards-Reinforcement-Learning" class="headerlink" title="Towards Reinforcement Learning"></a>Towards Reinforcement Learning</h3><ul>
<li>条件：T和R未知，可以重复试验（episodes）</li>
<li>目标：找到最佳Policy。</li>
<li>常见概念：  
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/rl_1.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
</li>
</ul>
<p><strong>Model-Based Learning</strong>：较容易想到对T和R进行经验性建模，下面是例子。<br>    
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/rl_2.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  </p>
<ul>
<li><strong>Dyna-Q</strong>：维护一个依据真实经验进行模拟训练的Value图，每次真实交互后进行N次模拟更新，从而充分利用已有经验。这样会使得学习速度显著加快，策略收敛加快，适合于样本昂贵的场景。基本算法如下：  
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/rl_dq.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
</li>
</ul>
<p><strong>Model-Free Learning</strong>：不直接建模T和R，而是直接学习Value图。策略固定时也称为Passive Reinforcement Learning。</p>
<ol>
<li><strong>Direct Evaluation</strong>：在固定策略下对某状态采样得到的值直接取平均。由于没有利用MDP特征，学习耗时较长。</li>
<li><p><strong>Temporal Difference (Value) Learning</strong>：联合Policy Evaluation和指数平均移动，一次只更新单个状态。</p>
<script type="math/tex; mode=display">\begin{aligned}Sample:\; &sample=R(s,\pi(s),s')+\gamma V^\pi(s') \\ Update: \; &V^\pi(s)\leftarrow (1-\alpha)V^\pi(s)+\alpha sample=V^\pi(s)+\alpha(sample-V\pi(s)) \\ Error:\; &E=\frac{1}{2}(sample - V^\pi(s))^2\end{aligned}</script></li>
<li><p><strong>Q-Learning</strong>：利用TD Learning学习Q-Value图。</p>
<script type="math/tex; mode=display">Q(s,a)\leftarrow Q(s,a)+\alpha[R(s,a,s')+\gamma\max\nolimits_{a'}Q(s',a')-Q(s,a)]</script><p> 这是一种off-policy learning，即通过不同的policy学到了最佳policy。反之on-policy learning则是仅学习到policy涉及的值。</p>
</li>
<li><strong>SARSA</strong>：State-Aciton-Reward-State-Aciton，是一种on-policy learning。与Q-Learning的区别仅在于更新Q值时直接依据当前策略，即<script type="math/tex; mode=display">Q(s,a)\leftarrow Q(s,a)+\alpha[R(s,a,s')+\gamma Q(s',a')-Q(s,a)]</script></li>
</ol>
<p><strong>Exploration</strong>：既需要学习到未走过的区域，又要保持较优的策略。</p>
<ol>
<li><strong>Random Actions</strong>：每一步以小概率$\epsilon$随机行动，其余概率以最佳策略行动。为了最后能仅执行最佳策略，可以随时间减小$\epsilon$。</li>
<li><p><strong>Exploration Function</strong>：奖励未经探索或鲜少探索的状态，这种奖励会随探索次数增加而逐渐降低，如</p>
<script type="math/tex; mode=display">\begin{aligned}&f(u,n)=u+k/n \\ &Q(s,a)\leftarrow_\alpha R(s,a,s')+\gamma\max\nolimits_{\alpha'}f(Q(s',a'),N(s',a'))\end{aligned}</script><p> <strong>Regret</strong>是当前策略获得的奖励和最佳策略奖励（事后之明）的误差，前两种探索方式中后一种的Regret更小，因为额外奖励。</p>
</li>
</ol>
<p><strong>Generalizing States</strong>：由于复杂问题或者真实世界中状态几乎无限多，我们可以用有限种情况来估计所有情况的Q-Value。</p>
<ol>
<li>States或Q-state可以使用特征向量来建模，每个维度描述了某个状态中的某个特征，如离终点的距离、敌人距离、局部环境特征等等。</li>
<li><p>Linear Value Function：用特征和权重对Value和Q-Value进行一阶线性表示</p>
<script type="math/tex; mode=display">V_w(s)=w_1f_1(s)+w_2f_2(s)+...+W_nf_n(s) \\ Q_w(s,a)=w_1f_1(s,a)+w_2f_2(s,a)+...+w_nf_n(s,a)</script><p> 权重的更新则可以通过对Error求偏导计算，非线性表示的更新规则相同</p>
<script type="math/tex; mode=display">\begin{aligned}w_i\leftarrow w_i-\alpha\frac{\partial Error(w_1,...,w_n)}{\partial w_i}=w_i-\alpha(Q_w(s,a)-sample)f_i(s,a)\end{aligned}</script><p> NN的引入可以构造更复杂的表示函数，知名案例有Deep Q-Networks、AlphaGo等。</p>
</li>
</ol>
<p><strong>思考</strong>：实际上，以上所有对Value的更新过程可以看作一种对贝尔曼方程（如下）的解的逼近做法，看起来类似于自回归，但单个Value仅为一个方程解，而自回归是在拟合一个关于时间的函数，所以两者有本质区别。</p>
<script type="math/tex; mode=display">V^*(s)=\mathcal{E}[r+\gamma V^*(s')]</script><p>参考PPT：<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_16_RL_I.pdf">RL_I</a>和<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_17_RL_II.pdf">RL_II</a></p>
<h2 id="Probabilistic-Graphical-Models"><a href="#Probabilistic-Graphical-Models" class="headerlink" title="Probabilistic Graphical Models"></a>Probabilistic Graphical Models</h2><h3 id="Bayesian-Nets"><a href="#Bayesian-Nets" class="headerlink" title="Bayesian Nets"></a>Bayesian Nets</h3><p>贝叶斯网络用节点表示随机变量，用有向连接的父子关系表示条件概率，显然为DAG。联合概率即被表示为：</p>
<script type="math/tex; mode=display">P(X_1,...,X_N)=\prod\nolimits_i P(X_i|Parents(X_i))</script>
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/bn_2.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>描述所有联合变量情况的表太过庞大，其中许多关系并非必要，这也使得贝叶斯网络过于庞大。我们利用<strong>条件独立</strong>（Conditional Independence）削减网络规模。</p>
<div class="admonition note"><p class="admonition-title">条件独立
</p><p>如是否下雨、是否交通拥堵和是否打伞三个二元随机变量，虽然下雨大概率导致交通拥堵和打伞，但是有了是否下雨这个条件后交通拥堵与打伞间没有必然联系，因而是否交通拥堵和是否打伞关于是否下雨相互条件独立。这种关系比变量间的独立性更容易存在，因为它精细地描述了事物间的因果关系，排除了一些不重要的联系。条件独立用符号表示为：<br>
$$\forall x,y,z; P(x|y,z)=P(x|z) ; or ; P(x,y|z)=P(x|z)P(y|z)$$</p>
</div>

<p>运用条件独立的贝叶斯网络中有两种常见结构：</p>
<ol>
<li><strong>共同原因</strong>：$X\leftarrow Y \rightarrow Z: P(x,y,z)=P(y)P(x|y)P(z|y)$，已知Y后X与Z相互条件独立，这表明观察到的共同原因会阻断效果间依赖，证明：<script type="math/tex; mode=display">P(z|x,y)=\frac{P(x,y,z)}{P(x,y)}=\frac{P(y)P(x|y)P(z|y)}{P(y)P(x|y)}=P(z|y)</script></li>
<li><strong>共同效果</strong>：$X\rightarrow Z \leftarrow Y: P(x,y,z)=P(x)P(y)P(z|x,y)$，X和Y相互独立，但已知Z后X、Y不一定相互独立，这表明观察到的共同效果会激发两个原因的依赖关系，独立性的证明：<script type="math/tex; mode=display">P(x,y)=\sum_z P(x,y,z)=\sum_z P(x)P(y)P(z|x,y)=P(x)P(y)</script></li>
</ol>
<p><strong>贝叶斯球</strong>（Bayes Ball）：一种在贝叶斯网络里判断已知条件下变量间是否相互条件独立的方法，步骤：</p>
<ol>
<li>给已知随机变量<strong>着色</strong></li>
<li>在某个待判断变量处放置一个球</li>
<li>球能以任意方向通过active path，而被inactive path阻挡</li>
<li>球可达另一待判断变量，则表明这两个变量在已知条件下<strong>不条件独立</strong></li>
</ol>
<p>Active Path与Inactive Path：主要是根据共同原因、共同效果和链状连接的性质进行判断<br>
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/bn_1.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  </p>
<p><strong>Markov Blanket</strong>：变量的马尔可夫毯包含它的父节点、子节点和子节点的其他父节点，已知它的马尔科夫毯会使其与其他所有变量条件独立。</p>
<p><strong>Normalization</strong>：有时我们比较同一已知条件的条件概率大小，此时跳过其分母，如</p>
<script type="math/tex; mode=display">P(Q|e)=\frac{\sum_{h_1}\sum_{h_2}P(Q,h_1,h_2,e)}{P(e)}\propto\sum_{h_1}\sum_{h_2}P(Q,h_1,h_2,e)</script><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Variable_elimination"><strong>Variable Elimination</strong></a>：一种简单的精确条件概率（Exact Inference from Conditional Probability Table）算法，其思想是列出所有隐藏变量并优先将它们通过求和消除，这过程中隐藏变量的顺序会影响最后逐点相乘的计算量，找到最优顺序是NP-hard问题。算法框架如下</p>
<figure class="highlight stylus"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">function <span class="hljs-built_in">VariableElimination</span>(Q , e, bn) returns <span class="hljs-selector-tag">a</span> distribution over Q<br>    factors ← <span class="hljs-selector-attr">[ ]</span><br>    <span class="hljs-keyword">for</span> each <span class="hljs-selector-tag">var</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">ORDER</span>(bn.vars) do<br>        factors ← <span class="hljs-selector-attr">[MAKE-FACTOR(var, e)|factors]</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-selector-tag">var</span> is <span class="hljs-selector-tag">a</span> hidden variable then<br>            factors ← <span class="hljs-built_in">SUM-OUT</span>(<span class="hljs-selector-tag">var</span>,factors)<br>    return <span class="hljs-built_in">NORMALIZE</span>(<span class="hljs-built_in">POINTWISE-PRODUCT</span>(factors))<br></code></pre></td></tr></table></figure>
<p><strong>Sampling</strong>：与精确相对，Approximate Inference from CPT，有以下几种采样方法</p>
<ol>
<li><strong>Prior Sampling</strong>：对贝叶斯网络中的所有变量进行采样，采样和概率算法如下 <figure class="highlight stata"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stata">w=1.0<br><span class="hljs-keyword">For</span> i=1, 2, …, <span class="hljs-keyword">n</span><br>    <span class="hljs-keyword">Sample</span> <span class="hljs-keyword">xi</span> from P(<span class="hljs-keyword">Xi</span>| Parents(<span class="hljs-keyword">Xi</span>))<br>    w = w * P(<span class="hljs-keyword">xi</span>| Parents(<span class="hljs-keyword">Xi</span>))<br><span class="hljs-keyword">Return</span> (x1, x2, …, xn), w<br></code></pre></td></tr></table></figure></li>
<li><strong>Rejection Sampling</strong>：为求条件概率，丢弃所有不合条件的采样，算法如下 <figure class="highlight stata"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs stata"><span class="hljs-keyword">IN</span>: evidence instantiation<br><span class="hljs-keyword">For</span> i=1, 2, …, <span class="hljs-keyword">n</span><br>    <span class="hljs-keyword">Sample</span> <span class="hljs-keyword">xi</span> from P(<span class="hljs-keyword">Xi</span>| Parents(<span class="hljs-keyword">Xi</span>))<br>    <span class="hljs-keyword">If</span> <span class="hljs-keyword">xi</span> not consistent with evidence<br>        Reject: <span class="hljs-keyword">Return</span>, and <span class="hljs-keyword">no</span> <span class="hljs-keyword">sample</span> is generated <span class="hljs-keyword">in</span> this cycle<br><span class="hljs-keyword">Return</span> (x1, x2, …, xn)<br></code></pre></td></tr></table></figure></li>
<li><strong>Likelihood Weighting</strong>：为充分利用采样，通过先验条件变量的概率给予权重，采样非条件变量，从而达到固定条件变量的目的，算法如下 <figure class="highlight stata"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stata"><span class="hljs-keyword">IN</span>: evidence instantiation<br>w = 1.0<br><span class="hljs-keyword">for</span> i=1, 2, …, <span class="hljs-keyword">n</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">Xi</span> is <span class="hljs-keyword">an</span> evidence variable<br>        <span class="hljs-keyword">xi</span> = observation <span class="hljs-keyword">xi</span> <span class="hljs-keyword">for</span> <span class="hljs-keyword">Xi</span><br>        <span class="hljs-keyword">Set</span> w = w * P(<span class="hljs-keyword">xi</span>| Parents(<span class="hljs-keyword">Xi</span>))<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">Sample</span> <span class="hljs-keyword">xi</span> from P(<span class="hljs-keyword">Xi</span>| Parents(<span class="hljs-keyword">Xi</span>))<br><span class="hljs-keyword">return</span> (x1, x2, …, xn), w<br></code></pre></td></tr></table></figure></li>
<li><strong>Gibbs Sampling</strong>：为充分利用已知的先验变量和已抽取的后验变量，我们每次仅对一个非条件变量进行采样，并以固定的先验值和采样过的后验值为条件，v重复此采样过程。采样中可以每隔一定采样次数计入一个采样，以达到采样稳态分布的目的。这是一种Markov Chain Monte Carlo方法，对复杂的多维变量概率问题非常有效。算法框架如下： <figure class="highlight livecodeserver"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">IN: Arbitrary instantiation consistent <span class="hljs-keyword">with</span> <span class="hljs-keyword">the</span> evidence<br><span class="hljs-keyword">for</span> k(technically infinite) sampling times<br>    Resample xi <span class="hljs-built_in">from</span> P(Xi| all other variables) <span class="hljs-keyword">for</span> Xi <span class="hljs-keyword">not</span> <span class="hljs-keyword">among</span> <span class="hljs-keyword">the</span> evidence variables<br></code></pre></td></tr></table></figure>
</li>
</ol>
<p>参考PPT：<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_18_Bayes_Nets_inked.pdf">Bayes Nets</a>, <a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_19_Bayes_Nets_Independence.pdf">Bayes Nets Independence</a>, <a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_20_Bayes_Nets_Inference_inked.pdf">Bayes Nets Inference</a>, <a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_21_Bayes_Nets_Sampling_inked.pdf">Bayes Nets Sampling</a></p>
<h3 id="Hidden-Markov-Models"><a href="#Hidden-Markov-Models" class="headerlink" title="Hidden Markov Models"></a>Hidden Markov Models</h3><p>在贝叶斯网络的基础上，从时间或空间的角度上观察一个随机变量（或称状态）序列，或者说一个（一阶）马尔可夫链，我们有以下基本假设：</p>
<ul>
<li>状态转移概率来自一个稳态分布</li>
<li>以现在状态为条件时，过去状态与未来状态相互独立</li>
<li>每个状态只依赖上一个状态</li>
</ul>
<p>马尔可夫链的状态转移公式很简单：</p>
<script type="math/tex; mode=display">\begin{aligned}P(X_t)&=\sum_{x_{t-1},...,x_0}P(X_t|x_{t-1})P(x_{t-1}|x_{t-2})...P(x_0) \\ &=\sum_{x_{t-1}}P(X_t|x_{t-1})\sum_{x_{t-2},...,x_0}P(x_0,...,x_{t-1}) \\ &=\sum_{x_{t-1}}P(X_t|x_{t-1})P(x_{t-1})\end{aligned}</script><p><strong>隐马尔可夫模型</strong>（HMM）中，状态是不直接可见的，只能观察到由当前状态引发的先验，现实中语音识别、机器翻译等等都是这种模型。精确查询HMM的联合分布可以用以下公式：</p>
<script type="math/tex; mode=display">P(X_0,X_1,E_1,...,X_T,E_T)=P(X_0)\prod_{t=1:T}P(X_t|X_{t-1})P(E_t|X_t)</script>
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/bn_3.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  
<p>除联合分布外，精确查询HMM通常有以下几种情况：<br>
    <figure class="figure-image">
      <img src="/images/2025/intro-ai/bn_4.png" alt="" loading="lazy" />
      <figcaption></figcaption>
    </figure>
  </p>
<p>其中Filtering可以看作以现在和过去的先验为条件，当前的状态的条件概率，其公式推导过程如下：</p>
<script type="math/tex; mode=display">\begin{aligned}P(X_t|e_{1:t}) &=P(X_t|e_t, e_{1:t-1}) \\ &=\alpha P(X_t,e_t|e_{1:t-1}) \\ &=\alpha \sum_{x_{t-1}}P(x_{t-1},X_t,e_t|e_{1:t-1}) \\ &=\alpha \sum_{x_{t-1}}P(x_{t-1}|e_{1:t-1})P(X_t|x_{t-1})P(e_t|X_t) \\ &=\alpha(normalize) \; P(e_t|X_t)(update) \; \sum_{x_{t-1}}P(x_t|x_{t-1})P(x_{t-1}|e_{1:t-1})(predict) \\ &recursively\; computing\; ... \end{aligned}</script><p>时间和空间复杂度为$O(|X|^2), \;|X|$是状态数，通常非常大。</p>
<p><strong>Particle Filtering</strong>：从状态极多甚至连续的空间中近似查询HMM的方法，其核心思想是。该方法为求$p(x_t|e_{1:t})$，首先随机进行N个采样（或称粒子），接下来在三个步骤间循环：</p>
<ol>
<li>预测：直接根据状态转移模型生成新粒子，$x_t^{i}~p(x_t|x_{t-1}^i)$。</li>
<li>权重更新：根据观测调整所有粒子的可信度（初始为1），$\tilde{w}_t^i=w_{t-1}^i\cdot p(e_t|x_t^i)$，再归一化$w_t^i=\tilde{w}_t^i/(\sum_{j=1}^N \tilde{w}_t^j)$。</li>
<li>重采样：按照新权重重新采样N个粒子，从而将粒子聚集到权重大的状态，淘汰权重小的状态，解决粒子退化的问题。</li>
</ol>
<p>在第二步中更新得到的权重和第三步中重采样的粒子实际在$|X|=N$的空间内近似计算了$p(x_t|e_{1:t})$：</p>
<script type="math/tex; mode=display">p(x_{t}|e_{1:t})\approx \sum\nolimits_{i=1}^N w_t^i\delta(x_t-x_t^i)</script><p>参考PPT：<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_22_Bayes_Nets_HMMs_inked.pdf">Bayes Nets HMMs</a>, <a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~15281-f19/lectures/15281_Fa19_Lecture_23_HMMs_and_Particle_Filters_inked.pdf">HMMs and Particle Filters</a></p>

      </section>

      
      
        <nav class="article-nav">
          
            <div class="article-nav-item layout-padding">
  <article class="card-container article-nav-card content-padding--primary soft-size--large soft-style--box">
    
    <div class="card-text">
      
        <a href="/posts/51146/" itemprop="url">
          <h2 class="card-text--title text-ellipsis">渲染手册</h2>
        </a>
      
      <div class="card-text--row">下一篇</div>
    </div>
  </article>
</div>
          
          
            <div class="article-nav-item layout-padding">
  <article class="card-container article-nav-card content-padding--primary soft-size--large soft-style--box">
    
    <div class="card-text">
      
        <a href="/posts/7678/" itemprop="url">
          <h2 class="card-text--title text-ellipsis">算术编码（AC）代码详解</h2>
        </a>
      
      <div class="card-text--row">上一篇</div>
    </div>
  </article>
</div>
          
        </nav>
      

      <section class="page-message-container layout-padding">
        


  
  
    <div class="valine-container comments-container content-padding--primary soft-size--large soft-style--box">
      <div id="valine_thread" class="valine-thread"></div>
    </div>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/leancloud-storage@3.15.0/dist/av-min.min.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script>
    <script type="text/javascript">
      new Valine({
        el: "#valine_thread",
        appId: "KyFX86e0JECKvlIZxD5t3gvy-gzGzoHsz",
        appKey: "vUaIlHWvvCWkewgmtQCSLh4B",
        placeholder: "跟我交流一下叭～",
        avatar: "mp",
        pageSize: 10,
        lang: "zh-cn",
        visitor: true,
        recordIP: false,
        enableQQ: false,
        meta: ['nick', 'mail'],
        requiredFields: ['nick'],
        
        // Bilibili 表情包插件
        // 设置 Bilibili 表情包地址
        emojiCDN: '//i0.hdslb.com/bfs/emote/', 
        // 表情 title 和图片映射
        emojiMaps: {
            // 小黄脸
            "2023": "fa6dda8b876ed38609de38aa604be5ad109b8591.png",
            "足球": "f9157d9fa5ac3b8339cb8a8b7ad70eb40d4113c9.png",
            "脱单doge": "bf7e00ecab02171f8461ee8cf439c73db9797748.png",
            "微笑": "685612eadc33f6bc233776c6241813385844f182.png",
            "口罩": "3ad2f66b151496d2a5fb0a8ea75f32265d778dd3.png",
            "doge": "3087d273a78ccaff4bb1e9972e2ba2a7583c9f11.png",
            "妙啊": "b4cb77159d58614a9b787b91b1cd22a81f383535.png",
            "OK": "4683fd9ffc925fa6423110979d7dcac5eda297f4.png",
            "星星眼": "63c9d1a31c0da745b61cdb35e0ecb28635675db2.png",
            "辣眼睛": "35d62c496d1e4ea9e091243fa812866f5fecc101.png",
            "吃瓜": "4191ce3c44c2b3df8fd97c33f85d3ab15f4f3c84.png",
            "滑稽": "d15121545a99ac46774f1f4465b895fe2d1411c3.png",
            "呲牙": "b5a5898491944a4268360f2e7a84623149672eb6.png",
            "打call": "431432c43da3ee5aab5b0e4f8931953e649e9975.png",
            "歪嘴": "4384050fbab0586259acdd170b510fe262f08a17.png",
            "调皮": "8290b7308325e3179d2154327c85640af1528617.png",
            "2022": "a783df2ce72952c44004007462324bde4b092a0c.png",
            "虎年": "a062f5fa2bafe677e49b6963a2bbb11dd4fe1e11.png",
            "豹富": "3d1dbe52ea16e12ff7b1c371196f728a4097fb33.png",
            "嗑瓜子": "28a91da1685d90124cfeead74622e1ebb417c0eb.png",
            "笑哭": "c3043ba94babf824dea03ce500d0e73763bf4f40.png",
            "藏狐": "ba0937ef6f3ccca85e2e0047e6263f3b4da37201.png",
            "脸红": "0922c375da40e6b69002bd89b858572f424dcfca.png",
            "给心心": "1597302b98827463f5b75c7cac1f29ea6ce572c4.png",
            "嘟嘟": "abd7404537d8162720ccbba9e0a8cdf75547e07a.png",
            "哦呼": "362bded07ea5434886271d23fa25f5d85d8af06c.png",
            "喜欢": "8a10a4d73a89f665feff3d46ca56e83dc68f9eb8.png",
            "酸了": "92b1c8cbceea3ae0e8e32253ea414783e8ba7806.png",
            "嫌弃": "de4c0783aaa60ec03de0a2b90858927bfad7154b.png",
            "大哭": "2caafee2e5db4db72104650d87810cc2c123fc86.png",
            "害羞": "9d2ec4e1fbd6cb1b4d12d2bbbdd124ccb83ddfda.png",
            "疑惑": "b7840db4b1f9f4726b7cb23c0972720c1698d661.png",
            "喜极而泣": "485a7e0c01c2d70707daae53bee4a9e2e31ef1ed.png",
            "奸笑": "bb84906573472f0a84cebad1e9000eb6164a6f5a.png",
            "笑": "81edf17314cea3b48674312b4364df44d5c01f17.png",
            "偷笑": "6c49d226e76c42cd8002abc47b3112bc5a92f66a.png",
            "惊讶": "f8e9a59cad52ae1a19622805696a35f0a0d853f3.png",
            "捂脸": "6921bb43f0c634870b92f4a8ad41dada94a5296d.png",
            "阴险": "ba8d5f8e7d136d59aab52c40fd3b8a43419eb03c.png",
            "囧": "12e41d357a9807cc80ef1e1ed258127fcc791424.png",
            "呆": "33ad6000d9f9f168a0976bc60937786f239e5d8c.png",
            "抠鼻": "cb89184c97e3f6d50acfd7961c313ce50360d70f.png",
            "大笑": "ca94ad1c7e6dac895eb5b33b7836b634c614d1c0.png",
            "惊喜": "0afecaf3a3499479af946f29749e1a6c285b6f65.png",
            "无语": "44667b7d9349957e903b1b62cb91fb9b13720f04.png",
            "点赞": "1a67265993913f4c35d15a6028a30724e83e7d35.png",
            "鼓掌": "895d1fc616b4b6c830cf96012880818c0e1de00d.png",
            "尴尬": "cb321684ed5ce6eacdc2699092ab8fe7679e4fda.png",
            "灵魂出窍": "43d3db7d97343c01b47e22cfabeca84b4251f35a.png",
            "委屈": "d2f26cbdd6c96960320af03f5514c5b524990840.png",
            "傲娇": "010540d0f61220a0db4922e4a679a1d8eca94f4e.png",
            "疼": "905fd9a99ec316e353b9bd4ecd49a5f0a301eabf.png",
            "冷": "cb0ebbd0668640f07ebfc0e03f7a18a8cd00b4ed.png",
            "热": "4e58a2a6f5f1580ac33df2d2cf7ecad7d9ab3635.png",
            "生病": "0f25ce04ae1d7baf98650986454c634f6612cb76.png",
            "吓": "9c10c5ebc7bef27ec641b8a1877674e0c65fea5d.png",
            "吐": "06946bfe71ac48a6078a0b662181bb5cad09decc.png",
            "捂眼": "c5c6d6982e1e53e478daae554b239f2b227b172b.png",
            "嘘声": "e64af664d20716e090f10411496998095f62f844.png",
            "思考": "cfa9b7e89e4bfe04bbcd34ccb1b0df37f4fa905c.png",
            "再见": "fc510306bae26c9aec7e287cdf201ded27b065b9.png",
            "翻白眼": "eba54707c7168925b18f6f8b1f48d532fe08c2b1.png",
            "哈欠": "888d877729cbec444ddbd1cf4c9af155a7a06086.png",
            "奋斗": "bb2060c15dba7d3fd731c35079d1617f1afe3376.png",
            "墨镜": "3a03aebfc06339d86a68c2d893303b46f4b85771.png",
            "难过": "a651db36701610aa70a781fa98c07c9789b11543.png",
            "撇嘴": "531863568e5668c5ac181d395508a0eeb1f0cda4.png",
            "抓狂": "4c87afff88c22439c45b79e9d2035d21d5622eba.png",
            "生气": "3195714219c4b582a4fb02033dd1519913d0246d.png",
            "水稻": "d530fcaa5100ba12a17a79b55bad342d530c54e3.png",
            "奶茶干杯": "d5a491990be551ce69f9660da948050df4eab331.png",
            "汤圆": "93609633a9d194cf336687eb19c01dca95bde719.png",
            "锦鲤": "643d6c19c8164ffd89e3e9cdf093cf5d773d979c.png",
            "弹幕破百亿": "80891223ba023dff3141e377f4ea3b89918eb6a4.png",
            "福到了": "5de5373d354c373cf1617b6b836f3a8d53c5a655.png",
            "鸡腿": "c7860392815d345fa69c4f00ef18d67dccfbd574.png",
            "雪花": "a41813c4edf8782047e172c884ebd4507ce5e449.png",
            "视频卫星": "dce6fc7d6dfeafff01241924db60f8251cca5307.png",
            "干杯": "8da12d5f55a2c7e9778dcc05b40571979fe208e6.png",
            "黑洞": "e90ec4c799010f25391179118ccd9f66b3b279ba.png",
            "爱心": "ed04066ea7124106d17ffcaf75600700e5442f5c.png",
            "胜利": "b49fa9f4b1e7c3477918153b82c60b114d87347c.png",
            "加油": "c7aaeacb21e107292d3bb053e5abde4a4459ed30.png",
            "抱拳": "89516218158dbea18ab78e8873060bf95d33bbbe.png",
            "响指": "1b5c53cf14336903e1d2ae3527ca380a1256a077.png",
            "保佑": "fafe8d3de0dc139ebe995491d2dac458a865fb30.png",
            "福": "802429a301ac5b35a0480d9526a070ce67cd8097.png",
            "支持": "3c210366a5585706c09d4c686a9d942b39feeb50.png",
            "拥抱": "41780a4254750cdaaccb20735730a36044e98ef3.png",
            "跪了": "f2b3aee7e521de7799d4e3aa379b01be032698ac.png",
            "怪我咯": "07cc6077f7f7d75b8d2c722dd9d9828a9fb9e46d.png",
            "老鼠": "8e6fb491eb1bb0d5862e7ec8ccf9a3da12b6c155.png",
            "牛年": "9275275ff1f2659310648221107d20bc4970f106.png",
            "三星堆": "fc7dadaa6986e75b813aa26f3eff3281d5f1a6d1.png",
            "洛天依": "9fe06f3594d9afaf4ee2b74770f1c3086ae0ba11.png",
            "坎公骑冠剑_吃鸡": "c4248a7b6ab326d66c83fd1fb58f1a50f99df332.png",
            "坎公骑冠剑_钻石": "0b97c7e50e0cc963370e62fbb9b55f51bbe7f8ab.png",
            "坎公骑冠剑_无语": "80eba0ce64c3fc1279b4daede2f1979cb2380e78.png",
            "来古-沉思": "4ee07ff03266d62b246be0b950bebb2abf3d997c.png",
            "来古-呆滞": "9a70b365e523f2379f395031ceefcebb75a45903.png",
            "来古-疑问": "032fdc0d9d9fe6334776f6c39518a959b73b98f4.png",
            "来古-震撼": "8b40f228675602a317d32007de6b795c101135ec.png",
            "来古-注意": "4b671ba32a2581cf40e5cd41c67b111eb8010de0.png",
            "初音未来_大笑": "8e7f71cda83ce407b0684702983399f8ed982f17.png",
            "原神_哇": "8188ddf95bace929d382c7a83214afde79d83bfc.png",
            "原神_哼": "91ed33b74bc36873c3ac8b2648f70d7ab6d8ab78.png",
            "原神_嗯": "8b0a87e414f453a29730b6e0f45ca61f2f898688.png",
            "原神_欸嘿": "8fba438fcbe0550877b04efd768d857082307c5e.png",
            "原神_喝茶": "1de5789fbb3526ef7823c54db7081790a38e7044.png",
            "原神_生气": "90a38c34742899f8e84138ed55f56cad3ba611fb.png",
            "保卫萝卜_白眼": "9fce63f38288700bf7be84f3be336cf895ba0902.png",
            "保卫萝卜_笔芯": "5ff2ed5cb71b02010018cc5910ac7052a03769af.png",
            "保卫萝卜_哭哭": "7d249f7c990111d3e2982f7477af15b7eb29cbd9.png",
            "保卫萝卜_哇": "5f2370e561c32d841245f7b1aab2eef43aeb9544.png",
            "保卫萝卜_问号": "41eb93f09fc4a4d0692a310e8a1f85ba60e96060.png",
            "无悔华夏_不愧是你": "c58002c32ee78d45366e126f294cb3149dd64ac2.png",
            "无悔华夏_吃瓜": "273dcff577551bafff4f1eae18561f871e73a6ba.png",
            "无悔华夏_达咩": "cffab383f47bab7f6736ba9c8d6ac098113410d9.png",
            "无悔华夏_点赞": "b0f2e8db405ec667c3e6aaabd7c15155b6ea8710.png",
            "无悔华夏_好耶": "324cd79784aeb37dbf2f47f68bbe8ed5d01f975e.png",
            "奥比岛_搬砖": "1fab697214918d91087373a999cc7ef8040ddf85.png",
            "奥比岛_点赞": "fb0b476fe2ff30cd59385ea7d616627ac114161f.png",
            "奥比岛_击爪": "35bba1bb8f164c5e844155548438248e6eaa8382.png",
            "奥比岛_委屈": "fda155e7c33b40dbb94c24644e0635d47b6ef3cc.png",
            "奥比岛_喜欢": "ed64e0c81ee194138bd9df30c65077ed978fb88c.png",
            // tv_小电视
            "tv_白眼": "c1d59f439e379ee50eef488bcb5e5378e5044ea4.png",
            "tv_doge": "6ea59c827c414b4a2955fe79e0f6fd3dcd515e24.png",
            "tv_坏笑": "1f0b87f731a671079842116e0991c91c2c88645a.png",
            "tv_难过": "87f46748d3f142ebc6586ff58860d0e2fc8263ba.png",
            "tv_生气": "26702dcafdab5e8225b43ffd23c94ac1ff932654.png",
            "tv_委屈": "d04dba7b5465779e9755d2ab6f0a897b9b33bb77.png",
            "tv_斜眼笑": "911f987aa8bc1bee12d52aafe62bc41ef4474e6c.png",
            "tv_呆": "fe1179ebaa191569b0d31cecafe7a2cd1c951c9d.png",
            "tv_发怒": "34ba3cd204d5b05fec70ce08fa9fa0dd612409ff.png",
            "tv_惊吓": "0d15c7e2ee58e935adc6a7193ee042388adc22af.png",
            "tv_呕吐": "9f996894a39e282ccf5e66856af49483f81870f3.png",
            "tv_思考": "90cf159733e558137ed20aa04d09964436f618a1.png",
            "tv_微笑": "70dc5c7b56f93eb61bddba11e28fb1d18fddcd4c.png",
            "tv_疑问": "0793d949b18d7be716078349c202c15ff166f314.png",
            "tv_大哭": "23269aeb35f99daee28dda129676f6e9ea87934f.png",
            "tv_鼓掌": "1d21793f96ef4e6f48b23e53e3b9e42da833a0f6.png",
            "tv_抠鼻": "c666f55e88d471e51bbd9fab9bb308110824a6eb.png",
            "tv_亲亲": "a8111ad55953ef5e3be3327ef94eb4a39d535d06.png",
            "tv_调皮": "b9c41de8e82dd7a8515ae5e3cb63e898bf245186.png",
            "tv_笑哭": "1abc628f6d4f4caf9d0e7800878f4697abbc8273.png",
            "tv_晕": "5443c22b4d07fb1907ccc610c8e6db254f2461b7.png",
            "tv_点赞": "f85c354995bd99e28fc76c869bfe42ba6438eff4.png",
            "tv_害羞": "a37683fb5642fa3ddfc7f4e5525fd13e42a2bdb1.png",
            "tv_睡着": "8b196675b53af58264f383c50ad0945048290b33.png",
            "tv_色": "61822c7e9aae5da76475e7892534545336b23a6f.png",
            "tv_吐血": "09dd16a7aa59b77baa1155d47484409624470c77.png",
            "tv_无奈": "ea8ed89ee9878f2fece2dda0ea8a5dbfe21b5751.png",
            "tv_再见": "180129b8ea851044ce71caf55cc8ce44bd4a4fc8.png",
            "tv_流汗": "cead1c351ab8d79e9f369605beb90148db0fbed3.png",
            "tv_偷笑": "bb690d4107620f1c15cff29509db529a73aee261.png",
            "tv_抓狂": "fe31c08edad661d63762b04e17b8d5ae3c71a757.png",
            "tv_黑人问号": "45821a01f51bc867da9edbaa2e070410819a95b2.png",
            "tv_困": "241ee304e44c0af029adceb294399391e4737ef2.png",
            "tv_打脸": "56ab10b624063e966bfcb76ea5dc4794d87dfd47.png",
            "tv_闭嘴": "c9e990da7f6e93975e25fd8b70e2e290aa4086ef.png",
            "tv_鄙视": "6e72339f346a692a495b123174b49e4e8e781303.png",
            "tv_腼腆": "89712c0d4af73e67f89e35cbc518420380a7f6f4.png",
            "tv_馋": "fc7e829b845c43c623c8b490ee3602b7f0e76a31.png",
            "tv_可爱": "9e55fd9b500ac4b96613539f1ce2f9499e314ed9.png",
            "tv_发财": "34db290afd2963723c6eb3c4560667db7253a21a.png",
            "tv_生病": "8b0ec90e6b86771092a498c54f09fc94621c1900.png",
            "tv_流鼻血": "c32d39db2737f89b904ca32700d140a9241b0767.png",
            "tv_尴尬": "7cfa62dafc59798a3d3fb262d421eeeff166cfa4.png",
            "tv_大佬": "093c1e2c490161aca397afc45573c877cdead616.png",
            "tv_流泪": "7e71cde7858f0cd50d74b0264aa26db612a8a167.png",
            "tv_冷漠": "b9cbc755c2b3ee43be07ca13de84e5b699a3f101.png",
            "tv_皱眉": "72ccad6679fea0d14cce648b4d818e09b8ffea2d.png",
            "tv_鬼脸": "0ffbbddf8a94d124ca2f54b360bbc04feb6bbfea.png",
            "tv_调侃": "4bc022533ef31544ca0d72c12c808cf4a1cce3e3.png",
            "tv_目瞪口呆": "0b8cb81a68de5d5365212c99375e7ace3e7891b7.png",
            // ... 更多表情
        }
        
      });
    </script>
  

  
  


      </section>
    </div>
    <div class="widget-info">
      <section class="widget-author widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-body">
    
      <img src="/images/const/avatar.png" class="soft-size--round soft-style--box" alt="猫才毛">
    
    
      <h2>猫才毛</h2>
    
    
      <p>Live for what I love ~</p>
    

    <div class="count-box">
      <div class="count-box--item">
        <svg class="icon icon-article" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M240.51564747 647.74217627h196.07203239c16.59071043 0 30.16492806-13.57421762 30.16492805-30.16492806V165.10332731c0-33.18142087-30.16492806-60.32985613-60.32985612-60.32985611H245.04038668C225.43318342 104.7734712 210.35071939 119.85593522 210.35071939 139.46313845V617.57724821c0 16.59071043 13.57421762 30.16492806 30.16492808 30.16492806z m663.62841731-452.47392089v482.63884894c0 33.18142087-27.14843525 60.32985613-60.32985612 60.32985613H180.18579134c-33.18142087 0-60.32985613-27.14843525-60.32985612-60.32985613V195.26825538c-49.77213131 0-90.49478418 40.72265287-90.49478417 90.49478417v452.4739209c0 49.77213131 40.72265287 90.49478418 90.49478417 90.49478417h286.56681657c16.59071043 0 30.16492806 13.57421762 30.16492807 30.16492807s13.57421762 30.16492806 30.16492805 30.16492806h90.49478418c16.59071043 0 30.16492806-13.57421762 30.16492805-30.16492806s13.57421762-30.16492806 30.16492807-30.16492807h286.56681657c49.77213131 0 90.49478418-40.72265287 90.49478417-90.49478417V285.76303955c0-49.77213131-40.72265287-90.49478418-90.49478417-90.49478417zM587.41232014 647.74217627h191.54729318c19.60720323 0 34.68966726-15.08246403 34.68966729-34.68966727V134.93839925c0-16.59071043-13.57421762-30.16492806-30.16492808-30.16492805H617.57724821c-30.16492806 0-60.32985613 27.14843525-60.32985612 60.32985611v452.4739209c0 16.59071043 13.57421762 30.16492806 30.16492805 30.16492806z" fill="currentColor"></path>
</svg>
        <span>16</span>
      </div>
      <div class="count-box--item">
        <svg class="icon icon-categories" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M900.3614811 257.09082106h-339.81629553l-67.96326003-101.9448889c-19.41807444-29.12711113-48.54518557-43.69066667-82.52681443-43.69066667H123.6385189c-53.39970333 0-97.09036999 43.69066667-97.09037113 97.09036999v582.54222222c0 53.39970333 43.69066667 97.09036999 97.09037113 97.09037002h776.7229622c53.39970333 0 97.09036999-43.69066667 97.09037113-97.09037002V354.18119104c0-53.39970333-43.69066667-97.09036999-97.09037113-97.09036998z m-97.09036999 242.72592554H220.72888889c-24.27259221 0-48.54518557-24.27259221-48.54518556-48.54518556s24.27259221-48.54518557 48.54518556-48.54518444h582.54222222c24.27259221 0 48.54518557 24.27259221 48.54518556 48.54518444s-24.27259221 48.54518557-48.54518556 48.54518556z" fill="currentColor"></path>
</svg>
        8
      </div>
      <div class="count-box--item">
        <svg class="icon icon-tags" viewBox="0 0 1098 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M283.42180005 272q0-28.38857157-20.09142843-48.48000001t-48.47999998-20.09142842-48.48000002 20.09142842-20.09142846 48.48000001 20.09142846 48.48 48.48000002 20.09142843 48.47999998-20.09142843 20.09142843-48.48zM855.0332285 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.03999997 263.58857157q-20.9142853 19.81714313-48.75428534 19.81714312-28.38857157 0-48.20571468-19.81714312l-383.04-383.58857157q-20.36571468-19.81714313-34.55999999-54.10285688t-14.19428534-62.6742853l0-222.85714313q0-27.84000002 20.36571469-48.20571469t48.2057147-20.36571466l222.85714313 0q28.38857157 0 62.6742853 14.19428529t54.65142842 34.55999999l383.04000001 382.49142843q19.81714313 20.9142853 19.81714314 48.75428532zM1060.74751475 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.04 263.58857157q-20.9142853 19.81714313-48.75428531 19.81714312-19.26857155 0-31.61142843-7.47428531t-28.38857159-24.13714314l251.79428534-251.7942853q19.81714313-19.81714313 19.81714308-48.20571469 0-27.84000002-19.81714308-48.75428531l-383.04000001-382.49142845q-20.36571468-20.36571468-54.65142842-34.55999999t-62.67428532-14.19428534l120 0q28.38857157 0 62.67428532 14.19428534t54.65142842 34.55999999l383.03999998 382.49142845q19.81714313 20.9142853 19.81714314 48.75428531z" fill="currentColor"></path>
</svg>
        4
      </div>
    </div>
  </div>
</section>

      
<section class="widget-toc widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-toc" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M134.50666666 767.46666668H460.8c27.73333333 0 50.24000001 22.50666668 50.24000001 50.23999999v50.13333333c0 27.73333333-22.50666668 50.24000001-50.24000001 50.24000001H134.50666666c-27.73333333 0-50.24000001-22.50666668-50.23999999-50.24000001v-50.13333333c0.10666668-27.73333333 22.50666668-50.24000001 50.24000001-50.24000001zM84.37333332 541.65333333h326.18666669c27.73333333 0 50.24000001 22.39999999 50.23999999 50.13333334v50.24000001c0 27.73333333-22.50666668 50.24000001-50.24000002 50.23999999H84.37333332c-27.73333333 0-50.24000001-22.50666668-50.23999999-50.23999999v-50.24000001c0-27.73333333 22.50666668-50.13333334 50.24000001-50.13333334zM134.50666666 315.83999999H460.8c27.73333333 0 50.24000001 22.50666668 50.24000001 50.24000001v50.24000001c0 27.73333333-22.50666668 50.13333334-50.24000001 50.13333333H134.50666666c-27.73333333 0-50.24000001-22.39999999-50.23999999-50.13333333v-50.24000001c0.10666668-27.84000001 22.50666668-50.24000001 50.24000001-50.23999999zM209.81333332 89.91999999h326.18666671c27.73333333 0 50.24000001 22.39999999 50.23999997 50.13333335v50.23999999c0 27.73333333-22.50666668 50.24000001-50.24000001 50.24000001H209.81333332c-27.73333333 0-50.24000001-22.50666668-50.23999999-50.24000001v-50.24000001c0-27.73333333 22.50666668-50.13333334 50.24000001-50.13333333zM692.05333333 623.36l274.66666669 176.00000002c23.36000001 14.93333333 30.08 45.97333334 15.14666666 69.33333332L954.77333334 910.93333333c-14.93333333 23.25333334-45.97333334 30.08-69.33333335 15.14666667l-274.66666666-176c-23.36000001-14.93333333-30.08-45.97333334-15.14666667-69.33333333l27.09333334-42.24000001c14.93333333-23.36000001 46.08000001-30.08 69.33333333-15.14666666z" fill="currentColor"></path>
</svg>
    <span>TITLES</span>
  </div>
  <div class="widget-body">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%90%9C%E7%B4%A2"><span class="toc-text">搜索</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E7%AE%97%E6%B3%95"><span class="toc-text">A*算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Minimax"><span class="toc-text">Minimax</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hybrid-A"><span class="toc-text">Hybrid A*</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CSP%E9%97%AE%E9%A2%98%E4%B8%8EBacktracking"><span class="toc-text">CSP问题与Backtracking</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Local-Search"><span class="toc-text">Local Search</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reinforcement-Learning"><span class="toc-text">Reinforcement Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Markov-Decision-Process%EF%BC%88MDP%EF%BC%89"><span class="toc-text">Markov Decision Process（MDP）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Towards-Reinforcement-Learning"><span class="toc-text">Towards Reinforcement Learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Probabilistic-Graphical-Models"><span class="toc-text">Probabilistic Graphical Models</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Bayesian-Nets"><span class="toc-text">Bayesian Nets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hidden-Markov-Models"><span class="toc-text">Hidden Markov Models</span></a></li></ol></li></ol>
  </div>
</section>


      
<section class="widet-notice widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-notice" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M512 945.02305225v28.15620663a24.27259221 24.27259221 0 0 1-24.27259221 24.27259335H394.0352a48.54518557 48.54518557 0 0 1-41.74885888-23.78714112l-110.68302222-184.47170332a132.04290333 132.04290333 0 0 1-17.47626667-48.54518557h118.4502511a200.97706667 200.97706667 0 0 1 76.21594113 14.56355556l20.38897777 133.49925888a48.54518557 48.54518557 0 0 0 36.40888888 27.67075555l16.01991111 2.91271112a24.27259221 24.27259221 0 0 1 20.38897778 25.72894889zM997.45185223 463.45481443a194.18074112 194.18074112 0 0 1-38.8361489 116.50844445 24.75804445 24.75804445 0 0 1-36.4088889 0l-34.95253333-34.95253333a24.27259221 24.27259221 0 0 1-2.91271111-30.58346667 97.09036999 97.09036999 0 0 0 0-106.79940665 24.27259221 24.27259221 0 0 1 2.91271111-30.58346666l34.95253333-34.95253334a24.75804445 24.75804445 0 0 1 18.93262223-7.28177777 26.2144 26.2144 0 0 1 17.47626667 9.70903665A194.18074112 194.18074112 0 0 1 997.45185223 463.45481443z m-194.18074112-388.36148111v776.72296335a48.54518557 48.54518557 0 0 1-48.54518556 48.54518443h-28.64165888a48.54518557 48.54518557 0 0 1-33.98163001-14.07810332l-145.63555556-143.20829668A291.27111111 291.27111111 0 0 0 342.57730333 657.63555556H172.18370333a145.63555556 145.63555556 0 0 1-145.63555556-145.63555556v-97.09036999a145.63555556 145.63555556 0 0 1 145.63555556-145.63555556h170.3936a291.27111111 291.27111111 0 0 0 206.31703779-85.43952668l145.63555555-143.20829554a48.54518557 48.54518557 0 0 1 33.98162888-14.07810446H754.72592555a48.54518557 48.54518557 0 0 1 48.54518556 48.54518555z" fill="currentColor"></path>
</svg>
    <span>NOTICE</span>
  </div>
  <div class="widget-body">
    <p>欢迎访问阿毛的小书桌，我偶尔会更新自己的学习内容和项目经验，也有可能闲话生活！</p>
  </div>
</section>


      <section class="widget-categories widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-categories" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M900.3614811 257.09082106h-339.81629553l-67.96326003-101.9448889c-19.41807444-29.12711113-48.54518557-43.69066667-82.52681443-43.69066667H123.6385189c-53.39970333 0-97.09036999 43.69066667-97.09037113 97.09036999v582.54222222c0 53.39970333 43.69066667 97.09036999 97.09037113 97.09037002h776.7229622c53.39970333 0 97.09036999-43.69066667 97.09037113-97.09037002V354.18119104c0-53.39970333-43.69066667-97.09036999-97.09037113-97.09036998z m-97.09036999 242.72592554H220.72888889c-24.27259221 0-48.54518557-24.27259221-48.54518556-48.54518556s24.27259221-48.54518557 48.54518556-48.54518444h582.54222222c24.27259221 0 48.54518557 24.27259221 48.54518556 48.54518444s-24.27259221 48.54518557-48.54518556 48.54518556z" fill="currentColor"></path>
</svg>
      <span>CATEGORIES</span>
  </div>
  <div class="widget-body">
    <ul class="categories-list">
      
        <li class="categories-list-item">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">
            数据结构 (1)
          </a>
        </li>
        
        <li class="categories-list-item">
          <a href="/categories/MeshLab/">
            MeshLab (1)
          </a>
        </li>
        
        <li class="categories-list-item">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/">
            数据压缩 (3)
          </a>
        </li>
        
        <li class="categories-list-item">
          <a href="/categories/%E6%9D%82%E8%B0%88/">
            杂谈 (1)
          </a>
        </li>
        
        <li class="categories-list-item">
          <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
            学习笔记 (5)
          </a>
        </li>
        
        <li class="categories-list-item">
          <a href="/categories/%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/">
            信息收集 (1)
          </a>
        </li>
        
        <li class="categories-list-item">
          <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
            读书笔记 (1)
          </a>
        </li>
        
        <li class="categories-list-item">
          <a href="/categories/CG/">
            CG (1)
          </a>
        </li>
        
    </ul>
  </div>
</section>

      <section class="widget-tags widget-item  layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-tags" viewBox="0 0 1098 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M283.42180005 272q0-28.38857157-20.09142843-48.48000001t-48.47999998-20.09142842-48.48000002 20.09142842-20.09142846 48.48000001 20.09142846 48.48 48.48000002 20.09142843 48.47999998-20.09142843 20.09142843-48.48zM855.0332285 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.03999997 263.58857157q-20.9142853 19.81714313-48.75428534 19.81714312-28.38857157 0-48.20571468-19.81714312l-383.04-383.58857157q-20.36571468-19.81714313-34.55999999-54.10285688t-14.19428534-62.6742853l0-222.85714313q0-27.84000002 20.36571469-48.20571469t48.2057147-20.36571466l222.85714313 0q28.38857157 0 62.6742853 14.19428529t54.65142842 34.55999999l383.04000001 382.49142843q19.81714313 20.9142853 19.81714314 48.75428532zM1060.74751475 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.04 263.58857157q-20.9142853 19.81714313-48.75428531 19.81714312-19.26857155 0-31.61142843-7.47428531t-28.38857159-24.13714314l251.79428534-251.7942853q19.81714313-19.81714313 19.81714308-48.20571469 0-27.84000002-19.81714308-48.75428531l-383.04000001-382.49142845q-20.36571468-20.36571468-54.65142842-34.55999999t-62.67428532-14.19428534l120 0q28.38857157 0 62.67428532 14.19428534t54.65142842 34.55999999l383.03999998 382.49142845q19.81714313 20.9142853 19.81714314 48.75428531z" fill="currentColor"></path>
</svg>
    <span>TAGS</span>
  </div>
  <div class="widget-body">
    <div class="tags-cloud">
      <a href="/tags/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/" style="font-size: 10px;" class="tags-cloud-0">实用工具</a> <a href="/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E5%8E%8B%E7%BC%A9/" style="font-size: 20px;" class="tags-cloud-10">数字图像处理 压缩</a> <a href="/tags/%E8%B5%9B%E5%8D%9A%E5%85%AB%E8%82%A1/" style="font-size: 10px;" class="tags-cloud-0">赛博八股</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C/" style="font-size: 20px;" class="tags-cloud-10">项目经验</a>
    </div>
  </div>
</section>
    </div>
  </article>
</div>

    <!-- footer container -->
<footer id="footer" class="footer">
  <div class="footer-container">
    
    <div class="social-icons">
      
        
      
        
      
        
      
        
          <a href="https://github.com/AmaoLearning/" class="soft-size--primary soft-style--box" target="_blank" rel="noopener noreferrer">
            <svg class="icon icon-github" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M64.6 512c0 195.6 125.4 361.9 300.1 422.9 23.5 5.9 19.9-10.8 19.9-22.2v-77.6c-135.8 15.9-141.3-74-150.5-89-18.5-31.5-61.9-39.5-49-54.5 31-15.9 62.5 4 98.9 58 26.4 39.1 77.9 32.5 104.1 26 5.7-23.5 17.9-44.5 34.7-60.9-140.7-25.2-199.4-111.1-199.4-213.3 0-49.5 16.4-95.1 48.4-131.8-20.4-60.6 1.9-112.4 4.9-120.1 58.2-5.2 118.5 41.6 123.3 45.3 33.1-8.9 70.8-13.7 112.9-13.7 42.4 0 80.3 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.4-43.9 2.9 7.7 24.7 58.3 5.5 118.1 32.5 36.8 49 82.8 49 132.4 0 102.3-59 188.3-200.2 213.2 23.5 23.3 38.1 55.5 38.1 91.1v112.7c0.8 9 0 17.9 15.1 17.9C832.7 877 960.4 709.4 960.4 512.1c0-247.5-200.6-447.9-447.9-447.9C265 64.1 64.6 264.5 64.6 512z"></path>
</svg>
          </a>
        
      
        
      
    </div>
     
    <p>&copy; 2025 <a href="/" target="_blank">MaoCaiMao</a></p>

    

    <p>Powered by <a href="https://hexo.io" target="_blank" rel="noopener noreferrer">Hexo</a> Theme - <a href="https://github.com/miiiku/flex-block" target="_blank" rel="noopener noreferrer author">flex-block</a></p>

    <p>
      <a href="javascript:;" id="theme-light">🌞 浅色</a>
      <a href="javascript:;" id="theme-dark">🌛 深色</a>
      <a href="javascript:;" id="theme-auto">🤖️ 自动</a>
    </p>
  </div>
</footer>
  </div>

  <div class="back-to-top-fixed soft-size--round soft-style--box">
    <svg class="icon icon-back-to-top" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
      <path d="M725.333333 426.666667c-12.8 0-21.333333-4.266667-29.866667-12.8l-213.333333-213.333333c-17.066667-17.066667-17.066667-42.666667 0-59.733333s42.666667-17.066667 59.733333 0l213.333333 213.333333c17.066667 17.066667 17.066667 42.666667 0 59.733333C746.666667 422.4 738.133333 426.666667 725.333333 426.666667z"></path>
      <path d="M298.666667 426.666667c-12.8 0-21.333333-4.266667-29.866667-12.8-17.066667-17.066667-17.066667-42.666667 0-59.733333l213.333333-213.333333c17.066667-17.066667 42.666667-17.066667 59.733333 0s17.066667 42.666667 0 59.733333l-213.333333 213.333333C320 422.4 311.466667 426.666667 298.666667 426.666667z"></path>
      <path d="M512 896c-25.6 0-42.666667-17.066667-42.666667-42.666667L469.333333 170.666667c0-25.6 17.066667-42.666667 42.666667-42.666667s42.666667 17.066667 42.666667 42.666667l0 682.666667C554.666667 878.933333 537.6 896 512 896z"></path>
    </svg>
  </div>

  
  






<!-- copy button  -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script>

<!-- https://clipboardjs.com/ -->


<script type="text/javascript">
	(function () {
		function getCodeType (elem) {
			const classs = Array.from(elem.classList.values());
			if (classs && classs.length > 1) {
				return classs[1];
			}
			return "plain";
		}

		window.addEventListener("DOMContentLoaded", () => {
			const copyBtnClass = "copy-btn";
			//  instantiate clipboardjs 
			const clipboard = new ClipboardJS('.' + copyBtnClass);

			clipboard.on('success', function (e) {
				console.info('Action:', e.action);
				console.info('Text:', e.text);
				console.info('Trigger:', e.trigger);
				if (e.trigger) {
					e.trigger.classList.add("copied");
					setTimeout(() => {
						e.trigger.classList.remove("copied");
					}, 3000);
				}
				e.clearSelection();
			});

			clipboard.on('error', function (e) {
				console.error('Action:', e.action);
				console.error('Trigger:', e.trigger);
			});

			document.querySelectorAll('figure.highlight').forEach((elem) => {
				const codeContent = elem.querySelector("td.code");
				const copyButton = document.createElement('button');
				copyButton.setAttribute("class", copyBtnClass);
				copyButton.setAttribute("title", "Copy Code");
				copyButton.setAttribute("data-clipboard-text", codeContent.innerText);
				elem.insertBefore(copyButton, elem.children[0]);
			});
		})
	})();
</script>









  


  


  




<script src="/js/script.js"></script>


  
  <!-- 尾部用户自定义相关内容 -->
</body>
</html>
